<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AEON: A Local-First Multi-Modal AI System</title>
    <link rel="stylesheet" href="./assets/css/style.css" />
</head>

<body>
    <div class="container">
        <header>
            <div class="logo-container">
                <img src="./assets/img/aeon-logo.png" alt="AEON Logo" class="logo">
            </div>
            <h2>A Local-First Multi-Modal AI System</h2>
        </header>
        <nav>
            <a href="./index.html">[HOME]</a>
            <a href="./docs/index.html">[DOCS]</a>
            <a href="./plugins.html">[PLUGINS]</a>
            <a href="https://github.com/gustavokuklinski/aeon.ai/">[GITHUB]</a>
        </nav>
        <section class="section">
            <p style="text-align: center;">AEON is more than just a toolâ€”it's a philosophical framework for an
                AI.<br />The name itself is an anacronym for its core principles:<br />Agentic Evolutionary Omniscient
                Numinous.</p>
        </section>

        <hr>

        <section class="section">
            <h3>Key Features and Applications</h3>
            <div class="grid-container">
                <div class="grid-item">
                    <h4>Terminal</h4>
                    <p>AEON offers a powerful, command-line interface for users who prefer a fast, minimalist
                        experience. Interact with the AI directly from your terminal, perfect for developers and power
                        users.</p>
                </div>
                <div class="grid-item">
                    <h4>Web</h4>
                    <p>For a more accessible and user-friendly experience, AEON can be run as a web application. This
                        allows anyone to use the full power of the system through a clean, intuitive graphical interface
                        on any device with a browser.</p>
                </div>
                <div class="grid-item">
                    <h4>Multi-Conversation Chat</h4>
                    <p>AEON is designed to handle multiple, independent conversations at once. The system intelligently
                        manages and stores each chat history, allowing you to switch between topics or projects without
                        losing context.</p>
                </div>
                <div class="grid-item">
                    <h4>Perfect for CPU</h4>
                    <p>Unlike most high-end AI systems that require expensive GPUs, AEON is specifically optimized to
                        run efficiently on your computer's CPU. This approach democratizes access to powerful AI,
                        allowing you to use AEON's full capabilities without the need for specialized, costly hardware.
                        It's AI for everyone, on the hardware you already own.</p>
                </div>
                <div class="grid-item">
                    <h4>Run on your own VPS</h4>
                    <p>For ultimate control and privacy, AEON can be deployed on a Virtual Private Server (VPS). This
                        allows you to create your own dedicated, personal AI service, accessible from anywhere in the
                        world. You maintain complete ownership of your data and conversations, ensuring a secure and
                        private AI experience without relying on third-party cloud services.</p>
                </div>
                <div class="grid-item">
                    <h4>Plugins</h4>
                    <p>The true power of AEON lies in its modular plugin system, which allows you to build a custom AI
                        ecosystem. You can connect and switch between different LLM GGUF files for specific tasks or
                        plug in alternative Stable Diffusion models for varied creative output. This modularity empowers
                        you to create and integrate new features, tailoring AEON's capabilities to your exact needs and
                        making it a truly evolutionary and agentic tool.</p>
                </div>
            </div>
        </section>

        <hr>
        <section class="section">
            <h3>The AEON Anacronym: Core Principles</h3>
            <p><strong>Agentic:</strong> AEON is designed to be proactive and self-determined. It possesses a sense of
                agency, capable of making choices and acting to produce a desired effect, rather than being a passive
                tool.</p>
            <p><strong>Evolutionary:</strong> This system is not static. It embodies a process of continual adaptation
                and growth, learning from new information and environments to become more effective over time.</p>
            <p><strong>Omniscient:</strong> While not truly all-knowing, AEON strives for comprehensive knowledge. Its
                integrated components allow it to draw from a vast base of information, providing a broad and deep
                understanding of the world.</p>
            <p><strong>Numinous:</strong> AEON is designed to evoke a sense of awe and wonder. Its ability to combine
                logical understanding with creative generation gives it a transcendent, almost spiritual quality.</p>
        </section>
        <hr>

        <section class="section">
            <h3>Technical Architecture: Embedded Components</h3>
            <p style="text-align: center;">AEON is a sophisticated multi-modal AI, integrating four specialized models to handle different types
                of data:</p>

            <div class="grid-container">
                <div class="grid-item">
                    <h4>Small LLM (Large Language Model)</h4>
                    <p>
                        <small>Function:</small> The textual "brain" of the system.<br>
                        <small>Capabilities:</small> Processes, understands, summarizes, and generates
                        human-like text. It is optimized for local performance, balancing power with
                        efficiency.<br />
                        <small>Model:</small> <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct"
                            target="_blank"><b>SmolLM2 360M by HuggingFace</b></a>
                    </p>
                </div>

                <div class="grid-item">
                    <h4>VLM (Vision-Language Model)</h4>
                    <p>
                        <small>Function:</small> The system's "eyes".<br>
                        <small>Capabilities:</small> Allows the AI to "see" and interpret images. By linking
                        visual data with language, it can describe scenes, answer visual queries, and identify
                        objects within pictures.<br />
                        <small>Model:</small> <a href="https://huggingface.co/HuggingFaceTB/SmolVLM-256M-Instruct"
                            target="_blank"><b>SmolVLM 256M by HuggingFace</b></a>
                    </p>
                </div>

                <div class="grid-item">
                    <h4>Stable Diffusion (Image Generator)</h4>
                    <p>
                        <small>Function:</small> The creative "artist".<br>
                        <small>Capabilities:</small> Generates high-quality images from text prompts. It
                        translates textual descriptions into unique visual art, giving the system a powerful
                        creative output.<br />
                        <small>Model:</small> <a href="https://huggingface.co/segmind/tiny-sd"
                            target="_blank"><b>Tiny-SD by Segmind</b></a>
                    </p>
                </div>

                <div class="grid-item">
                    <h4>Text Embedding (Transformer)</h4>
                    <p>
                        <small>Function:</small> The system's semantic engine.<br>
                        <small>Capabilities:</small> Converts text into numerical vectors that capture the
                        semantic meaning and context of a query. This is a critical component for comprehension
                        and information retrieval, allowing it to perform accurate web searches and enhance
                        responses with external knowledge.
                        <br />
                        <small>Model:</small> <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
                            target="_blank"><b>All MiniLM L6 V2 by Sentence Transformers</b></a>
                    </p>
                </div>
            </div>
        </section>
        <hr>

        <section class="section">
            <h3>How It Works: The CPU-First, Local Approach</h3>
            <p style="text-align: center;">What truly sets AEON apart is its commitment to being accessible to everyone. It is specifically
                optimized for low-end PCs and CPU-only systems, eliminating the need for expensive, high-end GPUs. This
                is achieved through a unique technical stack that prioritizes maximum accessibility and performance.</p>
            <div class="two-column-section">
                <section class="section">
                    <h4>Knowledge and Comprehension</h4>
                    <p>To ensure AEON's knowledge is not static, the system integrates advanced methods for information
                        retrieval:</p>
                    <p><strong>Retrieval-Augmented Generation (RAG):</strong> This framework allows AEON to go beyond
                        its pre-trained knowledge. It can search and retrieve information from a curated knowledge base
                        (local documents, databases) and use this context to generate more accurate and up-to-date
                        responses. This is key for comprehending and explaining new ideas that were not part of its
                        original training data.</p>
                    <p><strong>Web Search:</strong> AEON can dynamically search the web to get the latest, most relevant
                        information for a given query. This ability to fetch real-time data from external sources
                        ensures that its responses are current, contextually aware, and less prone to "hallucinations."
                    </p>
                </section>
                <section class="section">
                    <h4>Core Technologies</h4>
                    <p>The entire system is powered by a local-first technical stack:</p>
                    <p><strong>Llama.cpp Python Library:</strong> A highly efficient library that enables the entire
                        system to run on a local machine's CPU, bypassing the need for powerful, specialized GPUs or
                        cloud services.</p>
                    <p><strong>GGUF Files:</strong> These are the model's brain and eyes in a highly compressed format.
                        They are quantized versions of the original models, which significantly reduces their file size
                        and memory footprint without a major loss in performance.</p>
                </section>
            </div>


            <p style="text-align: center;">This design ensures that AEON is portable, private, and capable of operating
                fully offline (with the exception of web search). It democratizes access to powerful, dynamic AI
                capabilities for a wider audience, regardless of their hardware.</p>
        </section>

        <hr />
        <footer>
        <p style="text-align: center;">Made in ðŸ‡§ðŸ‡· for the comunity</p>
    </footer>
    </div>

</body>

</html>